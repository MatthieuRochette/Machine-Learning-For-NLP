{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for NLP\n",
    "*This project requires Python 3.9+*\n",
    "### 1. Parsing and saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_parser import parse_data_to_csv\n",
    "\n",
    "raw_path = \"./original_data\"\n",
    "parsed_path = \"./parsed_data\"\n",
    "# parse_data_to_csv(raw_path, parsed_path) // DO NOT EXECUTE UNLESS PARSED DATA IS LOST, OR USE OTHER parsed_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading parsed data & Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from src.dataset import DataSet\n",
    "\n",
    "ds = DataSet(parsed_path)\n",
    "dummy_domain = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_polarity = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_rating_str = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Dummy classifier with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ds.training, ds.training.dtypes)\n",
    "dummy_domain.fit(ds.training[\"review_text\"], ds.training[\"domain\"])\n",
    "dummy_polarity.fit(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "dummy_rating_str.fit(ds.training[\"review_text\"], ds.training[\"rating_str\"].astype(str))  # column seems to automatically reconvert to float if not forced in str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and scores with Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_domain.predict(ds.testing[\"review_text\"]))\n",
    "print(dummy_polarity.predict(ds.testing[\"review_text\"]))\n",
    "print(dummy_rating_str.predict(ds.testing[\"review_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_domain.score(ds.testing[\"review_text\"], ds.testing[\"domain\"]))\n",
    "print(dummy_polarity.score(ds.testing[\"review_text\"], ds.testing[\"polarity\"]))\n",
    "print(dummy_rating_str.score(ds.testing[\"review_text\"], ds.testing[\"rating_str\"].astype(str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Example of Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  # CountVectorizer will be used later\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\")\n",
    "X_training = vectorizer.fit_transform(ds.training[\"review_text\"])\n",
    "print(X_training.shape)\n",
    "print(X_training.toarray())\n",
    "print(vectorizer.get_params(), vectorizer.get_stop_words(), sep='\\n')\n",
    "X_testing = vectorizer.transform(ds.testing[\"review_text\"])\n",
    "print(X_testing.shape)\n",
    "print(X_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Example of Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(shuffle=False)\n",
    "perceptron.fit(X_training, ds.training[\"polarity\"])\n",
    "perceptron.score(X_testing, ds.testing[\"polarity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preprocessing experiments\n",
    "\n",
    "We are going to use 2 different vectorizer types: TF-IDF and Count.  \n",
    "N-grams will be word based (= whitespace separated).  \n",
    "We are going to try different n-grams lengths: 1 to 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram_vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(1, 1))\n",
    "tfidf_bigram_vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(2, 2))\n",
    "tfidf_trigram_vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(3, 3))\n",
    "\n",
    "count_unigram_vectorizer = CountVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(1, 1))\n",
    "count_bigram_vectorizer = CountVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(2, 2))\n",
    "count_trigram_vectorizer = CountVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "base_perceptron = Perceptron()\n",
    "tfidf_unigram_perceptron = deepcopy(base_perceptron)  # deepcopying avoids having to copy parameters between multiple initializations\n",
    "tfidf_bigram_perceptron = deepcopy(base_perceptron)\n",
    "tfidf_trigram_perceptron = deepcopy(base_perceptron)\n",
    "count_unigram_perceptron = deepcopy(base_perceptron)\n",
    "count_bigram_perceptron = deepcopy(base_perceptron)\n",
    "count_trigram_perceptron = deepcopy(base_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_tfidf_unigram = tfidf_unigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_tfidf_unigram = tfidf_unigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_tfidf_bigram = tfidf_bigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_tfidf_bigram = tfidf_bigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_tfidf_trigram = tfidf_trigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_tfidf_trigram = tfidf_trigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "\n",
    "X_training_count_unigram = count_unigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_count_unigram = count_unigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_count_bigram = count_bigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_count_bigram = count_bigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_count_trigram = count_trigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_count_trigram = count_trigram_vectorizer.transform(ds.testing[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram_perceptron.fit(X_training_tfidf_unigram, ds.training[\"polarity\"])\n",
    "tfidf_bigram_perceptron.fit(X_training_tfidf_bigram, ds.training[\"polarity\"])\n",
    "tfidf_trigram_perceptron.fit(X_training_tfidf_trigram, ds.training[\"polarity\"])\n",
    "\n",
    "count_unigram_perceptron.fit(X_training_count_unigram, ds.training[\"polarity\"])\n",
    "count_bigram_perceptron.fit(X_training_count_bigram, ds.training[\"polarity\"])\n",
    "count_trigram_perceptron.fit(X_training_count_trigram, ds.training[\"polarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "s = \"\\t\\t\\tPrecision: {0:.9f}\\tRecall: {1:.9f}\\tF-Score: {2:.9f}\"\n",
    "\n",
    "\n",
    "def print_values(true_y, predicted_y, avg=\"macro\"):\n",
    "    values = precision_recall_fscore_support(true_y, predicted_y, average=avg)\n",
    "    print(s.format(*values))\n",
    "    return values\n",
    "\n",
    "\n",
    "print(\"Macro average values:\")\n",
    "\n",
    "print(\"\\tTFIDF vectorizer:\")\n",
    "print(\"\\t\\tUnigrams:\")\n",
    "print_values(ds.testing[\"polarity\"], tfidf_unigram_perceptron.predict(X_testing_tfidf_unigram))\n",
    "print(\"\\t\\tBigrams: \")\n",
    "print_values(ds.testing[\"polarity\"], tfidf_bigram_perceptron.predict(X_testing_tfidf_bigram))\n",
    "print(\"\\t\\tTrigrams:\")\n",
    "print_values(ds.testing[\"polarity\"], tfidf_trigram_perceptron.predict(X_testing_tfidf_trigram))\n",
    "print()\n",
    "print(\"\\tCounter vectorizer:\")\n",
    "print(\"\\t\\tUnigrams:\")\n",
    "print_values(ds.testing[\"polarity\"], count_unigram_perceptron.predict(X_testing_count_unigram))\n",
    "print(\"\\t\\tBigrams: \")\n",
    "print_values(ds.testing[\"polarity\"], count_bigram_perceptron.predict(X_testing_count_bigram))\n",
    "print(\"\\t\\tTrigrams:\")\n",
    "print_values(ds.testing[\"polarity\"], count_trigram_perceptron.predict(X_testing_count_trigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both vectorizer types have similar behaviors. Trigrams are clearly less accurate than unigrams or bigrams, but the difference between those last two is much thinner.  \n",
    "Apparently, bigrams work better than unigrams, although the delta is less than 1 or 2% in each vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_calc(domain, it=1000):\n",
    "    vec = TfidfVectorizer(lowercase=True, analyzer=\"word\")\n",
    "    training = vec.fit_transform(ds.training_by_domain[domain][\"review_text\"])\n",
    "    testing = vec.transform(ds.testing_by_domain[domain]['review_text'])\n",
    "    percep = Perceptron(shuffle=False, max_iter=it)\n",
    "    percep.fit(training, ds.training_by_domain[domain][\"polarity\"])\n",
    "    percep.score(testing, ds.testing_by_domain[domain][\"polarity\"])\n",
    "    print(s.format(*precision_recall_fscore_support(ds.testing_by_domain[domain][\"polarity\"], percep.predict(testing), average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_calc('books', 100)\n",
    "perceptron_calc('books', 1000)\n",
    "perceptron_calc('books', 10000)\n",
    "perceptron_calc('books', 100000)\n",
    "perceptron_calc('books', 1000000)\n",
    "perceptron_calc('books', 10000000)\n",
    "perceptron_calc('books', 100000000)\n",
    "perceptron_calc('books', 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_calc('dvd')\n",
    "perceptron_calc('electronics')\n",
    "perceptron_calc('kitchen & housewares')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. K-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "def print_values_for_n_neighbors(n, matrix=False):\n",
    "    training = ds.training.sample(frac=1, random_state=9)\n",
    "    testing = ds.testing.sample(frac=1, random_state=9)\n",
    "    kneighbors = KNeighborsClassifier(n_neighbors=n)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_training = vectorizer.fit_transform(training[\"review_text\"], training[\"domain\"])\n",
    "    X_testing = vectorizer.transform(testing[\"review_text\"])\n",
    "    kneighbors.fit(X_training, training[\"domain\"])\n",
    "    if not matrix:\n",
    "        return print_values(testing[\"domain\"], kneighbors.predict(X_testing))\n",
    "    else:\n",
    "        print_values(testing[\"domain\"], kneighbors.predict(X_testing))\n",
    "        return confusion_matrix(testing[\"domain\"], kneighbors.predict(X_testing), labels=testing[\"domain\"].unique())\n",
    "\n",
    "best_values = [0, 0, 0, None]\n",
    "best_n = 0\n",
    "\n",
    "def run_multiple_n_neighbors(range_: range):\n",
    "    global best_values, best_n\n",
    "    f_scores = []\n",
    "    for i in range_:\n",
    "        print(\"Number of neighbours:\", i)\n",
    "        values = print_values_for_n_neighbors(i)\n",
    "        f_scores.append(values[2])\n",
    "        if values[2] > best_values[2]:\n",
    "            best_values = values\n",
    "            best_n = i\n",
    "    plt.plot(range_, f_scores)\n",
    "\n",
    "run_multiple_n_neighbors(range(5, 200, 5))\n",
    "run_multiple_n_neighbors(range(250, 500, 50))\n",
    "run_multiple_n_neighbors(range(500, 3000, 500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot outputted here, we can see that the best range for the number of neighbors is between 10 and 200.\n",
    "Hereunder are the best results during this run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBest number of neighbors:\", best_n)\n",
    "print(\"Best values:\\n\", best_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = ds.training.sample(frac=1, random_state=9)\n",
    "testing = ds.testing.sample(frac=1, random_state=9)\n",
    "kneighbors = KNeighborsClassifier(n_neighbors=best_n)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_training = vectorizer.fit_transform(training[\"review_text\"], training[\"domain\"])\n",
    "X_testing = vectorizer.transform(testing[\"review_text\"])\n",
    "kneighbors.fit(X_training, training[\"domain\"])\n",
    "print(\"Macro averages for K-Neigbours classifier with K =\", best_n)\n",
    "matrix = print_values_for_n_neighbors(65, matrix=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 3)\n",
    "# hide axes\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "ax.table(matrix, loc=\"center\", colLabels=testing[\"domain\"].unique(), rowLabels=testing[\"domain\"].unique(), colLoc=\"center\")\n",
    "fig.tight_layout()\n",
    "print(\"Confusion matrix of K-Neighbours with K =\", best_n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "vec_nb = TfidfVectorizer(lowercase=True, analyzer=\"word\")\n",
    "X_training = vec_nb.fit_transform(ds.training['review_text'])\n",
    "X_testing = vec_nb.transform(ds.testing['review_text'])\n",
    "\n",
    "gnb = MultinomialNB()\n",
    "# print(X_training.shape, ds.training[\"rating\"].shape)\n",
    "gnb.fit(X_training, ds.training[\"rating\"])\n",
    "pred = gnb.predict(X_testing)\n",
    "print(pred)\n",
    "print_values(ds.testing[\"rating\"], pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "vec_dt = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "training_dt = vec_dt.fit_transform(ds.training[\"review_text\"])\n",
    "testing_dt = vec_dt.transform(ds.testing[\"review_text\"])\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(training_dt, ds.training[\"polarity\"]).score(testing_dt, ds.testing[\"polarity\"])\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], clf.predict(testing_dt), average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- max_depth: number of tree's nodes the higher the value, the higher and closer values are\n",
    "    - the higher the value, the higher and closer values are\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "vec_svm = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "training_svm = vec_svm.fit_transform(ds.training[\"review_text\"])\n",
    "testing_svm = vec_svm.transform(ds.testing[\"review_text\"])\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(training_svm, ds.training[\"polarity\"])\n",
    "clf.score(testing_svm, ds.testing[\"polarity\"])\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], clf.predict(testing_svm), average=\"macro\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "vec_svm = TfidfVectorizer(lowercase=True, analyzer=\"word\")\n",
    "training_svm = vec_svm.fit_transform(ds.training[\"review_text\"])\n",
    "testing_svm = vec_svm.transform(ds.testing[\"review_text\"])\n",
    "clf = svm.SVC(kernel=\"rbf\")\n",
    "clf.fit(training_svm, ds.training[\"polarity\"])\n",
    "clf.score(testing_svm, ds.testing[\"polarity\"])\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], clf.predict(testing_svm), average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Knowledge transfer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = ['dvd', 'kitchen & housewares', 'books', 'electronics']\n",
    "for domain in domain_list:\n",
    "    print(\"\\n\\n[trained]\", domain)\n",
    "    for d in domain_list:\n",
    "        vec = TfidfVectorizer(lowercase=True, analyzer=\"word\")\n",
    "        training = vec.fit_transform(ds.training_by_domain[domain][\"review_text\"])\n",
    "        testing = vec.transform(ds.testing_by_domain[d]['review_text'])\n",
    "        percep = Perceptron(shuffle=False)\n",
    "        percep.fit(training, ds.training_by_domain[domain][\"polarity\"])\n",
    "        percep.score(testing, ds.testing_by_domain[d][\"polarity\"])\n",
    "        print(\"=>[tested]\", d)\n",
    "        print(s.format(*precision_recall_fscore_support(ds.testing_by_domain[d][\"polarity\"], percep.predict(testing), average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Domain-Oblivious\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "domain_list = ['dvd', 'kitchen & housewares', 'books', 'electronics', 'all']\n",
    "for domain in domain_list:\n",
    "    print(\"\\n\\n[trained]\", domain)\n",
    "    for d in domain_list:\n",
    "        vec = TfidfVectorizer(lowercase=True, analyzer=\"word\")\n",
    "        training = vec.fit_transform(ds.training['review_text'] if domain == \"all\" else ds.training_by_domain[domain][\"review_text\"])\n",
    "        testing = vec.transform(ds.testing['review_text'] if d == 'all' else ds.testing_by_domain[d]['review_text'])\n",
    "        percep = Perceptron(shuffle=False)\n",
    "        percep.fit(training, ds.training['polarity'] if domain == 'all' else ds.training_by_domain[domain][\"polarity\"])\n",
    "        percep.score(testing, ds.testing['polarity'] if d == 'all' else ds.testing_by_domain[d]['polarity'])\n",
    "        print(\"=>[tested]\", d)\n",
    "        print(s.format(*precision_recall_fscore_support(ds.testing['polarity'] if d == 'all' else ds.testing_by_domain[d][\"polarity\"], percep.predict(testing), average=\"macro\")))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e99c606221478606e184a054e6047426ce52f9cc3eb14d6318f1ef08b00da85e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
