{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for NLP\n",
    "*This project requires Python 3.9+*\n",
    "### 1. Parsing and saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_parser import parse_data_to_csv\n",
    "\n",
    "raw_path = \"./original_data\"\n",
    "parsed_path = \"./parsed_data\"\n",
    "# parse_data_to_csv(raw_path, parsed_path) // DO NOT EXECUTE UNLESS PARSED DATA IS LOST, OR USE OTHER parsed_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading parsed data & Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from src.dataset import DataSet\n",
    "\n",
    "ds = DataSet(parsed_path)\n",
    "dummy_domain = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_polarity = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_rating_str = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Dummy classifier with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ds.training, ds.training.dtypes)\n",
    "dummy_domain.fit(ds.training[\"review_text\"], ds.training[\"domain\"])\n",
    "dummy_polarity.fit(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "dummy_rating_str.fit(ds.training[\"review_text\"], ds.training[\"rating_str\"].astype(str))  # column seems to automatically reconvert to float if not forced in str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and scores with Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_domain.predict(ds.testing[\"review_text\"]))\n",
    "print(dummy_polarity.predict(ds.testing[\"review_text\"]))\n",
    "print(dummy_rating_str.predict(ds.testing[\"review_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_domain.score(ds.testing[\"review_text\"], ds.testing[\"domain\"]))\n",
    "print(dummy_polarity.score(ds.testing[\"review_text\"], ds.testing[\"polarity\"]))\n",
    "print(dummy_rating_str.score(ds.testing[\"review_text\"], ds.testing[\"rating_str\"].astype(str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Example of Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  # CountVectorizer will be used later\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "X_training = vectorizer.fit_transform(ds.training[\"review_text\"])\n",
    "print(X_training.shape)\n",
    "print(X_training.toarray())\n",
    "print(vectorizer.get_params(), vectorizer.get_stop_words(), sep='\\n')\n",
    "X_testing = vectorizer.transform(ds.testing[\"review_text\"])\n",
    "print(X_testing.shape)\n",
    "print(X_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Example of Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(shuffle=False)\n",
    "perceptron.fit(X_training, ds.training[\"polarity\"])\n",
    "perceptron.score(X_testing, ds.testing[\"polarity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preprocessing experiments\n",
    "\n",
    "We are going to use 2 different vectorizer types: TF-IDF and Count.  \n",
    "N-grams will be word based (= whitespace separated).  \n",
    "We are going to try different n-grams lengths: 1 to 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram_vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(1, 1))\n",
    "tfidf_bigram_vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(2, 2))\n",
    "tfidf_trigram_vectorizer = TfidfVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(3, 3))\n",
    "\n",
    "count_unigram_vectorizer = CountVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(1, 1))\n",
    "count_bigram_vectorizer = CountVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(2, 2))\n",
    "count_trigram_vectorizer = CountVectorizer(lowercase=True, analyzer=\"word\", ngram_range=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "base_perceptron = Perceptron(shuffle=False)\n",
    "tfidf_unigram_perceptron = deepcopy(base_perceptron)  # deepcopying avoids having to copy parameters between multiple initializations\n",
    "tfidf_bigram_perceptron = deepcopy(base_perceptron)\n",
    "tfidf_trigram_perceptron = deepcopy(base_perceptron)\n",
    "count_unigram_perceptron = deepcopy(base_perceptron)\n",
    "count_bigram_perceptron = deepcopy(base_perceptron)\n",
    "count_trigram_perceptron = deepcopy(base_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_tfidf_unigram = tfidf_unigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_tfidf_unigram = tfidf_unigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_tfidf_bigram = tfidf_bigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_tfidf_bigram = tfidf_bigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_tfidf_trigram = tfidf_trigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_tfidf_trigram = tfidf_trigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "\n",
    "X_training_count_unigram = count_unigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_count_unigram = count_unigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_count_bigram = count_bigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_count_bigram = count_bigram_vectorizer.transform(ds.testing[\"review_text\"])\n",
    "X_training_count_trigram = count_trigram_vectorizer.fit_transform(ds.training[\"review_text\"], ds.training[\"polarity\"])\n",
    "X_testing_count_trigram = count_trigram_vectorizer.transform(ds.testing[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram_perceptron.fit(X_training_tfidf_unigram, ds.training[\"polarity\"])\n",
    "tfidf_bigram_perceptron.fit(X_training_tfidf_bigram, ds.training[\"polarity\"])\n",
    "tfidf_trigram_perceptron.fit(X_training_tfidf_trigram, ds.training[\"polarity\"])\n",
    "\n",
    "count_unigram_perceptron.fit(X_training_count_unigram, ds.training[\"polarity\"])\n",
    "count_bigram_perceptron.fit(X_training_count_bigram, ds.training[\"polarity\"])\n",
    "count_trigram_perceptron.fit(X_training_count_trigram, ds.training[\"polarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(\"Macro average values:\")\n",
    "s = \"\\t\\t\\tPrecision: {0}\\tRecall: {1}\\tF-Score: {2}\"\n",
    "\n",
    "print(\"\\tTFIDF vectorizer:\")\n",
    "print(\"\\t\\tUnigrams:\")\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], tfidf_unigram_perceptron.predict(X_testing_tfidf_unigram), average=\"macro\")))\n",
    "print(\"\\t\\tBigrams: \")\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], tfidf_bigram_perceptron.predict(X_testing_tfidf_bigram), average=\"macro\")))\n",
    "print(\"\\t\\tTrigrams:\")\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], tfidf_trigram_perceptron.predict(X_testing_tfidf_trigram), average=\"macro\")))\n",
    "print()\n",
    "print(\"\\tCounter vectorizer:\")\n",
    "print(\"\\t\\tUnigrams:\")\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], count_unigram_perceptron.predict(X_testing_count_unigram), average=\"macro\")))\n",
    "print(\"\\t\\tBigrams: \")\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], count_bigram_perceptron.predict(X_testing_count_bigram), average=\"macro\")))\n",
    "print(\"\\t\\tTrigrams:\")\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], count_trigram_perceptron.predict(X_testing_count_trigram), average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both vectorizer types have similar behaviors. Trigrams are clearly less accurate than unigrams or bigrams, but the difference between those last two is harder to understand.  \n",
    "Apparently, bigrams work better with the TF-IDF vectorizer, when unigrams are the best choice when paired with a Counter vectorizer, although the difference between the two is thin (a delta of less than 2% in each vectorizer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def perceptron_calc(domain, it):\n",
    "    vec = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "    training = vec.fit_transform(ds.training_by_domain[domain][\"review_text\"])\n",
    "    testing = vec.transform(ds.testing_by_domain[domain]['review_text'])\n",
    "    percep = Perceptron(shuffle=False, max_iter=it)\n",
    "    percep.fit(training, ds.training_by_domain[domain][\"polarity\"])\n",
    "    percep.score(testing, ds.testing_by_domain[domain][\"polarity\"])\n",
    "    print(s.format(*precision_recall_fscore_support(ds.testing_by_domain[domain][\"polarity\"], percep.predict(testing), average=\"macro\")))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Books"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perceptron_calc('books', 100)\n",
    "perceptron_calc('books', 1000)\n",
    "perceptron_calc('books', 10000)\n",
    "perceptron_calc('books', 100000)\n",
    "perceptron_calc('books', 1000000)\n",
    "perceptron_calc('books', 10000000)\n",
    "perceptron_calc('books', 100000000)\n",
    "perceptron_calc('books', 1000000000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DVD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perceptron_calc('dvd')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Electronics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perceptron_calc('electronics')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Kitchen And Housewares"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perceptron_calc('kitchen & housewares')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "vec_nb = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "nb_train_data = vec_nb.transform(ds.training['review_text'])\n",
    "nb_train_result = ds.training['rating_str']\n",
    "books_nb_test = vec_nb.transform(ds.testing_by_domain['books']['review_text'])\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pred = gnb.fit(nb_train_data, nb_train_result).predict(books_nb_test)\n",
    "print(pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Trees"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "vec_dt = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "training_dt = vec_dt.fit_transform(ds.training[\"review_text\"])\n",
    "testing_dt = vec_dt.transform(ds.testing[\"review_text\"])\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(training_dt, ds.training[\"polarity\"]).score(testing_dt, ds.testing[\"polarity\"])\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], clf.predict(testing_dt), average=\"macro\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- max_depth: number of tree's nodes the higher the value, the higher and closer values are\n",
    "    - the higher the value, the higher and closer values are\n",
    "-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Machines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Linear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "vec_svm = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "training_svm = vec_svm.fit_transform(ds.training[\"review_text\"])\n",
    "testing_svm = vec_svm.transform(ds.testing[\"review_text\"])\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(training_svm, ds.training[\"polarity\"])\n",
    "clf.score(testing_svm, ds.testing[\"polarity\"])\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], clf.predict(testing_svm), average=\"macro\")))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RBF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "vec_svm = TfidfVectorizer(lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "training_svm = vec_svm.fit_transform(ds.training[\"review_text\"])\n",
    "testing_svm = vec_svm.transform(ds.testing[\"review_text\"])\n",
    "clf = svm.SVC(kernel=\"rbf\")\n",
    "clf.fit(training_svm, ds.training[\"polarity\"])\n",
    "clf.score(testing_svm, ds.testing[\"polarity\"])\n",
    "print(s.format(*precision_recall_fscore_support(ds.testing[\"polarity\"], clf.predict(testing_svm), average=\"macro\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e99c606221478606e184a054e6047426ce52f9cc3eb14d6318f1ef08b00da85e"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}